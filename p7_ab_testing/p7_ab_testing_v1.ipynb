{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##0. Experiment Design\n",
    "\n",
    "###Metric Choice\n",
    "\n",
    "###Evaluation Metrics:\n",
    "\n",
    "####Gross Conversion\n",
    "The number of user-ids to complete checkout and enroll in the free trial divided by number of unique cookies to click the \"Start free trial\" button. In order to launch the product change, we'd need an absolute minimum difference of 0.01.\n",
    "\n",
    "Why an evaluation metric: Since the two branches of traffic would see/not see the screener, the metric would tell us how the new screener affect enrollment in the class.\n",
    "\n",
    "Why not an invariant metric: Since the two branches of traffic would see/not see the screener, we'd not expect the metric to be the same between the two branches.\n",
    "\n",
    "####Net Conversion\n",
    "The number of user-ids to remain enrolled past the 14-day boundary (and thus make at least one payment) divided by the number of unique cookies to click the \"Start free trial\" button. In order to launch the product change, we'd need absolute minimum difference of 0.0075.\n",
    "\n",
    "Why an evaluation metric: Since the two branches of traffic would see/not see the screener, the metric would tell us if the screener has an effect on the retention of students in the class.\n",
    "\n",
    "Why not an invariant metric: Since the two branches of traffic would see/not see the screener, we'd not expect the metric to be the same between the two branches.\n",
    "\n",
    "\n",
    "###Invariant Metrics:\n",
    "\n",
    "####Number of cookies\n",
    "The number of unique cookies to view the course overview page. Since the traffic is randomly split, we'd expect the same number of cookies.\n",
    "\n",
    "Why not an evaluation metric: Since the two branches of traffic are randomly split and have not reached the screener (or the lack thereof), we'd not expect there to be a difference.\n",
    "\n",
    "Why an invariant metric: Since the two branches of traffic are randomly split and have not reached the screener (or the lack thereof), we'd expect them to be the same.\n",
    "\n",
    "####Number of clicks\n",
    "The number of unique cookies to click the \"Start free trial\" button (which happens before the free trial screener is trigger). Since this step occurs before the free trial screener, we'd expect the same number of cookies in both traffic streams.\n",
    "\n",
    "Why not an evaluation metric: Since the two branches of traffic are randomly split and have not reached the screener (or the lack thereof), we'd not expect there to be a difference.\n",
    "\n",
    "Why an invariant metric: Since the two branches of traffic are randomly split and have not reached the screener (or the lack thereof), we'd expect them to be the same.\n",
    "\n",
    "###Neither Evaluation nor Invariant Metrics:\n",
    "\n",
    "####Number of user-ids\n",
    "The number of users who enroll in the free trial.\n",
    "\n",
    "Why not an evaluation metric: Since Gross Conversion already captures enrollment, this metric is extraneous.\n",
    "\n",
    "Why not an invariant metric: Since the two branches of traffic would see/not see the screener, we'd not expect this metric to be the same between the two branches.\n",
    "\n",
    "####Click-through-probability \n",
    "The number of unique cookies to click the \"Start free trial\" button divided by number of unique cookies to view the course overview page.\n",
    "\n",
    "Why not an evaluation metric: Since the two branches of traffic are randomly split and have not reached the screener (or the lack thereof), we'd not expect there to be a difference.\n",
    "\n",
    "Why not an invariant metric: Since the metric is a product of the number of cookies and number of clicks, this metric is extraneous.\n",
    "\n",
    "####Retention\n",
    "The number of user-ids to remain enrolled past the 14-day boundary (and thus make at least one payment) divided by number of user-ids to complete checkout. \n",
    "\n",
    "Why not an evaluation metric: Since Net Conversion already captures retention, this metric is extraneous.\n",
    "\n",
    "Why not an invariant metric: Since the two branches of traffic would see/not see the screener, we'd not expect this metric to be the same between the two branches."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##1. Measuring Standard Deviation\n",
    "\n",
    "Standard deviation of evaluation metrics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from math import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "baseline_values = pd.read_csv('Final Project Baseline Values - Sheet1.csv', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "baseline_values = baseline_values.set_index(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "baseline_values['sample_size'] = baseline_values[1] * (5000/40000.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>sample_size</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Unique cookies to view page per day:</th>\n",
       "      <td> 40000.000000</td>\n",
       "      <td> 5000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Unique cookies to click \"Start free trial\" per day:</th>\n",
       "      <td>  3200.000000</td>\n",
       "      <td>  400.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Enrollments per day:</th>\n",
       "      <td>   660.000000</td>\n",
       "      <td>   82.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Click-through-probability on \"Start free trial\":</th>\n",
       "      <td>     0.080000</td>\n",
       "      <td>    0.010000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Probability of enrolling, given click:</th>\n",
       "      <td>     0.206250</td>\n",
       "      <td>    0.025781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Probability of payment, given enroll:</th>\n",
       "      <td>     0.530000</td>\n",
       "      <td>    0.066250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Probability of payment, given click</th>\n",
       "      <td>     0.109313</td>\n",
       "      <td>    0.013664</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                1  sample_size\n",
       "0                                                                             \n",
       "Unique cookies to view page per day:                 40000.000000  5000.000000\n",
       "Unique cookies to click \"Start free trial\" per day:   3200.000000   400.000000\n",
       "Enrollments per day:                                   660.000000    82.500000\n",
       "Click-through-probability on \"Start free trial\":         0.080000     0.010000\n",
       "Probability of enrolling, given click:                   0.206250     0.025781\n",
       "Probability of payment, given enroll:                    0.530000     0.066250\n",
       "Probability of payment, given click                      0.109313     0.013664"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.20625\n",
      "0.020230604137\n",
      "82.5\n"
     ]
    }
   ],
   "source": [
    "# Gross Conversion\n",
    "\n",
    "p_hat = baseline_values.loc['Probability of enrolling, given click:', 1]\n",
    "N = baseline_values.loc['Unique cookies to click \"Start free trial\" per day:', 'sample_size']\n",
    "SE_p = sqrt(p_hat*(1-p_hat)/(N))\n",
    "print p_hat\n",
    "print SE_p\n",
    "print p_hat * N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1093125\n",
      "0.0156015445825\n",
      "43.725\n"
     ]
    }
   ],
   "source": [
    "# Net Conversion\n",
    "\n",
    "p_hat = baseline_values.loc['Probability of payment, given click', 1]\n",
    "N = baseline_values.loc['Unique cookies to click \"Start free trial\" per day:', 'sample_size']\n",
    "SE_p = sqrt(p_hat*(1-p_hat)/(N))\n",
    "print p_hat\n",
    "print SE_p\n",
    "print p_hat * N"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For both of the evaluation metrics, the analytical estimate is likely comparable to the empirical estimate. Since clicks and enrollments are binomial variables, with p_hat * N > 5 and (1-p_hat) * N > 5, we can use the normal distribution to approximate them which is what we're assuming with the analytical estimate. If there's a slight difference, the analytical estimate would be an underestimate of the variance.\n",
    "\n",
    "Furthermore, the unit of analyses (the denominator, i.e. cookies) and our unit of diversion for the experiment (i.e. cookies) are the same, therefore we can be confident about using the analytical estimate for the variance. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##2. Sizing\n",
    "\n",
    "Given we have 2 metrics, using the Bonferonni correction is the right way to ensure that the result of the hypothesis test is not due to chance. However, it will take too long for the experiment to achieve enough power (using beta = 0.2 and alpha = 0.05). \n",
    "\n",
    "To calculate the number of pageviews required, the baseline p_hat and the absolute minimum difference are plugged into this [calculator](http://www.evanmiller.org/ab-testing/sample-size.html). The results are below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "683625.0\n"
     ]
    }
   ],
   "source": [
    "# Net Conversion\n",
    "\n",
    "sample_size_per_branch = 27345\n",
    "pageviews = baseline_values.loc['Unique cookies to view page per day:', 1]\n",
    "clicks = baseline_values.loc['Unique cookies to click \"Start free trial\" per day:', 1]\n",
    "print sample_size_per_branch*2 * (pageviews / float(clicks)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "645300.0\n"
     ]
    }
   ],
   "source": [
    "# Gross Conversion\n",
    "\n",
    "sample_size_per_branch = 25812\n",
    "pageviews = baseline_values.loc['Unique cookies to view page per day:', 1]\n",
    "clicks = baseline_values.loc['Unique cookies to click \"Start free trial\" per day:', 1]\n",
    "print sample_size_per_branch*2 * (pageviews / float(clicks)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'd take the larger one 683625."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Duration vs. Exposure\n",
    "Since it is a relatively low risk experiment, I'd split the traffic 50-50 to conduct the experiment. A 50-50 split is the highest amount of traffic you can divert into the experiment and control group. This is required due to the high number of pageviews required to establish statistical power for the hypothesis test. Even doing so would take 35 days to complete the experiment given the number of pageviews needed and daily traffic. However, given the benefit of better retaining the users enrolled in the course (i.e. reducing churn), it would be beneficial to run it for that long. Since the cost of acuiring a customer (in this case, the online marketing campaigns, etc.) is often much higher than the cost of retaining a customer (in this case, understanding if there's anything that can be done to influence the customer to stay), such a long experiment would be worth running."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##3. Experiment Analysis\n",
    "###Sanity Checks\n",
    "For each of your invariant metrics, the 95% confidence interval for the value you expect to observe contains the actual observed value, therefore the metric passes the sanity check. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "control = pd.read_csv('Final Project Results - Control.csv')\n",
    "experiment = pd.read_csv('Final Project Results - Experiment.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Date  Pageviews  Clicks  Enrollments  Payments\n",
      "0  Sat, Oct 11       7723     687          134        70\n",
      "1  Sun, Oct 12       9102     779          147        70\n",
      "2  Mon, Oct 13      10511     909          167        95\n",
      "3  Tue, Oct 14       9871     836          156       105\n",
      "4  Wed, Oct 15      10014     837          163        64\n"
     ]
    }
   ],
   "source": [
    "print control.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Since we'd need enrollment and payment information, we only use pageviews and clicks\n",
    "# for the first 24 days.\n",
    "\n",
    "pageviews_control = sum(control['Pageviews'])\n",
    "pageviews_experiment = sum(experiment['Pageviews'])\n",
    "clicks_control = sum(control['Clicks'])\n",
    "clicks_experiment = sum(experiment['Clicks'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "interval:  (0.49882039214902313, 0.5011796078509769)\n",
      "observed:  0.500639666881\n"
     ]
    }
   ],
   "source": [
    "# pageviews\n",
    "\n",
    "SD = sqrt(0.5*0.5/float(pageviews_control + pageviews_experiment))\n",
    "margin_of_error = 1.96 * SD # assuming 95% C.I\n",
    "CI_LB = 0.5 - margin_of_error\n",
    "CI_UB = 0.5 + margin_of_error\n",
    "print 'interval: ', (CI_LB, CI_UB)\n",
    "print 'observed: ', (pageviews_control) / float(pageviews_control + pageviews_experiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "interval:  (0.49588449572378945, 0.5041155042762105)\n",
      "observed:  0.500467347407\n"
     ]
    }
   ],
   "source": [
    "# clicks\n",
    "\n",
    "SD = sqrt(0.5*0.5/float(clicks_control + clicks_experiment))\n",
    "margin_of_error = 1.96 * SD # assuming 95% C.I\n",
    "CI_LB = 0.5 - margin_of_error\n",
    "CI_UB = 0.5 + margin_of_error\n",
    "print 'interval: ', (CI_LB, CI_UB)\n",
    "print 'observed: ', (clicks_control) / float(clicks_control + clicks_experiment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##4. Result Analysis\n",
    "\n",
    "####Effect Size Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Gross Conversion\n",
    "\n",
    "enrollments_control = sum(control['Enrollments'][:23])\n",
    "enrollments_experiment = sum(experiment['Enrollments'][:23])\n",
    "\n",
    "N_cont = float(clicks_control)\n",
    "N_exp = float(clicks_experiment)\n",
    "X_cont = enrollments_control\n",
    "X_exp = enrollments_experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "interval:  (-0.029123358335404401, -0.01198639082531873)\n"
     ]
    }
   ],
   "source": [
    "p_hat = (X_cont + X_exp) / (N_cont + N_exp)\n",
    "SE_pool = sqrt((p_hat)*(1 - p_hat)*(1/N_cont + 1/N_exp))\n",
    "d_hat = X_exp/N_exp - X_cont/N_cont\n",
    "margin_of_error = SE_pool * 1.96 \n",
    "CI_LB = d_hat - margin_of_error\n",
    "CI_UB = d_hat + margin_of_error\n",
    "print 'interval: ', (CI_LB, CI_UB)\n",
    "\n",
    "# Since the CI does not contain 0, it's statistically significant. Since the UB's absolute value \n",
    "# is greater than the minimum desirable effect (i.e. 0.01), it's practically significant. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Net Conversion\n",
    "\n",
    "payments_control = sum(control['Payments'][:23])\n",
    "payments_experiment = sum(experiment['Payments'][:23])\n",
    "\n",
    "N_cont = float(clicks_control)\n",
    "N_exp = float(clicks_experiment)\n",
    "X_cont = payments_control\n",
    "X_exp = payments_experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "interval:  (-0.011604624359891718, 0.001857179010803383)\n"
     ]
    }
   ],
   "source": [
    "p_hat = (X_cont + X_exp) / (N_cont + N_exp)\n",
    "SE_pool = sqrt((p_hat)*(1 - p_hat)*(1/N_cont + 1/N_exp))\n",
    "d_hat = X_exp/N_exp - X_cont/N_cont\n",
    "margin_of_error = SE_pool * 1.96 \n",
    "CI_LB = d_hat - margin_of_error\n",
    "CI_UB = d_hat + margin_of_error\n",
    "print 'interval: ', (CI_LB, CI_UB)\n",
    "\n",
    "# Since the CI does contain 0, it's not statistically significant and therefore also not\n",
    "# practically significant"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####Sign Tests\n",
    "Based on the [sign test](http://graphpad.com/quickcalcs/binomial2/), at alpha = 0.05, the gross conversion effect is statistically significant since the 2-tailed p-value is less than 0.05 but the net conversion effect is not since its value is greater than 0.05."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "control['enrollments_clicks'] = control['Enrollments'] / control['Clicks']\n",
    "control['payments_clicks'] = control['Payments'] / control['Clicks']\n",
    "\n",
    "experiment['enrollments_clicks'] = experiment['Enrollments'] / experiment['Clicks']\n",
    "experiment['payments_clicks'] = experiment['Payments'] / experiment['Clicks']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of positives:  4\n"
     ]
    }
   ],
   "source": [
    "# Gross Conversion\n",
    "\n",
    "n_positives = sum((experiment['enrollments_clicks'] > control['enrollments_clicks'])[:23])\n",
    "n_days = 23\n",
    "print 'number of positives: ', n_positives\n",
    "\n",
    "# 2-tailed p-value = 0.0026"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of positives:  10\n"
     ]
    }
   ],
   "source": [
    "# Net Conversion\n",
    "\n",
    "n_positives = sum((experiment['payments_clicks'] > control['payments_clicks'])[:23])\n",
    "print 'number of positives: ', n_positives\n",
    "\n",
    "# 2-tailed p-value = 0.6776"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##5. Summary\n",
    "As stated above, the Bonferonni correction is not used because the experiment will simply take too long if it's used. The sign test and the effect size test agree with each other."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##6. Recommendation\n",
    "Since the Gross Conversion effect test is practically significant, we can conclude that having the extra free trial screener does have a visible business impact on the enrollment. In fact, it has a negative effect on the number of people that enroll in the course which is what we'd expect (we'd want it to decrease the number of students that wants to sign up but don't have the time to commit).\n",
    "\n",
    "As for the Net Conversion effect test, the result is not statistically significant; meaning the students that sign up after knowing that they'd need the time commitment does not necessarily continue to be enrolled. This requires additional thought and discussion with the product team. \n",
    "\n",
    "Before making plans to conduct additional experiments, it might be effective to have an exit survey when the student decide to cancel their subscription of the reason why they're cancelling. This will lead to better understanding of the students and better intuition in generating features that'd reduce churn."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
